{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Function 3: Calculate Station Statistics\n",
    "\n",
    "## Building the `calculate_station_statistics` Function\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand data aggregation and grouping operations in pandas\n",
    "- Learn to use `.groupby()` for statistical analysis\n",
    "- Master aggregate functions (mean, count, min, max)\n",
    "- Create summary DataFrames from grouped data\n",
    "- Handle missing data in statistical calculations\n",
    "- Generate meaningful reports from environmental monitoring data\n",
    "\n",
    "**Professional Context:**\n",
    "Data aggregation is crucial for:\n",
    "- **Summarizing large datasets** - Convert thousands of readings into actionable insights\n",
    "- **Identifying patterns** - Find which stations have unusual temperature or humidity patterns\n",
    "- **Quality control** - Identify stations with too few readings or extreme values\n",
    "- **Reporting** - Create executive summaries for stakeholders\n",
    "- **Decision making** - Determine where to place new monitoring stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Data Grouping\n",
    "\n",
    "### 1.1 What is Data Grouping?\n",
    "\n",
    "**Data grouping** is like organizing data into categories and then calculating statistics for each category.\n",
    "\n",
    "**Real-world example:**\n",
    "Imagine you have temperature readings from 5 weather stations, with multiple readings per day:\n",
    "\n",
    "```\n",
    "Raw Data (1000s of readings):\n",
    "station_id  | temperature_c | humidity_percent | datetime\n",
    "STN_001     | 22.5         | 65               | 2024-01-01 08:00\n",
    "STN_001     | 23.1         | 63               | 2024-01-01 12:00\n",
    "STN_002     | 18.9         | 72               | 2024-01-01 08:00\n",
    "STN_002     | 19.7         | 70               | 2024-01-01 12:00\n",
    "...\n",
    "\n",
    "Grouped Summary (5 stations):\n",
    "station_id  | avg_temperature | avg_humidity | reading_count\n",
    "STN_001     | 22.8           | 64.2         | 245\n",
    "STN_002     | 19.3           | 71.1         | 198\n",
    "STN_003     | 25.1           | 58.7         | 267\n",
    "```\n",
    "\n",
    "This transformation makes data **actionable** - you can now answer questions like:\n",
    "- Which station is the hottest on average?\n",
    "- Which station has the most/least data?\n",
    "- Are there patterns across different locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create realistic environmental monitoring data for demonstration\n",
    "def create_sample_environmental_data():\n",
    "    \"\"\"Create sample environmental monitoring data that mimics real weather station data.\"\"\"\n",
    "    \n",
    "    # Define weather stations with different characteristics\n",
    "    stations = {\n",
    "        'STN_001': {'base_temp': 22, 'base_humidity': 65, 'location': 'Downtown'},\n",
    "        'STN_002': {'base_temp': 19, 'base_humidity': 72, 'location': 'Coastal'},\n",
    "        'STN_003': {'base_temp': 25, 'base_humidity': 58, 'location': 'Desert'},\n",
    "        'STN_004': {'base_temp': 16, 'base_humidity': 78, 'location': 'Mountain'},\n",
    "        'STN_005': {'base_temp': 21, 'base_humidity': 68, 'location': 'Suburban'}\n",
    "    }\n",
    "    \n",
    "    # Generate readings for each station\n",
    "    all_data = []\n",
    "    \n",
    "    for station_id, props in stations.items():\n",
    "        # Different stations have different numbers of readings (realistic scenario)\n",
    "        n_readings = np.random.randint(150, 300)\n",
    "        \n",
    "        # Generate temperatures with daily and random variation\n",
    "        base_temp = props['base_temp']\n",
    "        temperatures = []\n",
    "        \n",
    "        for i in range(n_readings):\n",
    "            # Daily variation (warmer in afternoon)\n",
    "            hour_of_day = (i * 6) % 24  # Simulate readings every 6 hours\n",
    "            daily_variation = 3 * np.sin(2 * np.pi * hour_of_day / 24)\n",
    "            \n",
    "            # Random variation\n",
    "            random_variation = np.random.normal(0, 2)\n",
    "            \n",
    "            temp = base_temp + daily_variation + random_variation\n",
    "            temperatures.append(round(temp, 1))\n",
    "        \n",
    "        # Generate humidity with inverse correlation to temperature\n",
    "        base_humidity = props['base_humidity']\n",
    "        humidities = []\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            # Humidity tends to be lower when temperature is higher\n",
    "            temp_effect = -0.8 * (temp - base_temp)\n",
    "            random_variation = np.random.normal(0, 3)\n",
    "            \n",
    "            humidity = base_humidity + temp_effect + random_variation\n",
    "            humidity = max(30, min(95, humidity))  # Keep within realistic range\n",
    "            humidities.append(round(humidity, 1))\n",
    "        \n",
    "        # Add station data\n",
    "        for i in range(n_readings):\n",
    "            all_data.append({\n",
    "                'station_id': station_id,\n",
    "                'temperature_c': temperatures[i],\n",
    "                'humidity_percent': humidities[i],\n",
    "                'location': props['location']\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame and shuffle\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)  # Shuffle the data\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create our sample dataset\n",
    "environmental_data = create_sample_environmental_data()\n",
    "\n",
    "print(\"Sample Environmental Monitoring Data Created:\")\n",
    "print(f\"Total readings: {len(environmental_data):,}\")\n",
    "print(f\"Stations: {environmental_data['station_id'].nunique()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(environmental_data.head())\n",
    "\n",
    "print(\"\\nReadings per station:\")\n",
    "print(environmental_data['station_id'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Understanding the GroupBy Operation\n",
    "\n",
    "The `.groupby()` operation in pandas is like sorting data into buckets and then performing calculations on each bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate basic groupby concepts\n",
    "print(\"=== UNDERSTANDING GROUPBY ===\")\n",
    "\n",
    "# Step 1: See the unique stations\n",
    "unique_stations = environmental_data['station_id'].unique()\n",
    "print(f\"Unique stations: {list(unique_stations)}\")\n",
    "print(f\"Number of stations: {len(unique_stations)}\")\n",
    "\n",
    "# Step 2: Create groupby object\n",
    "grouped = environmental_data.groupby('station_id')\n",
    "print(f\"\\nGroupBy object created: {type(grouped)}\")\n",
    "print(f\"Number of groups: {grouped.ngroups}\")\n",
    "\n",
    "# Step 3: Show what's in each group\n",
    "print(\"\\nGroup information:\")\n",
    "for name, group in grouped:\n",
    "    print(f\"  Group '{name}': {len(group)} rows\")\n",
    "    # Show sample from first group\n",
    "    if name == unique_stations[0]:\n",
    "        print(f\"    Sample from {name}:\")\n",
    "        print(group[['temperature_c', 'humidity_percent', 'location']].head(3).to_string(index=False))\n",
    "        print(\"    ...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Calculating Aggregate Statistics\n",
    "\n",
    "### 2.1 Basic Aggregation Functions\n",
    "\n",
    "Once data is grouped, you can apply various aggregate functions to summarize each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different aggregation functions\n",
    "print(\"=== AGGREGATION FUNCTIONS ===\")\n",
    "\n",
    "grouped = environmental_data.groupby('station_id')\n",
    "\n",
    "# 1. Mean (average)\n",
    "avg_temperature = grouped['temperature_c'].mean()\n",
    "print(\"\\nAverage Temperature by Station:\")\n",
    "for station, avg_temp in avg_temperature.items():\n",
    "    print(f\"  {station}: {avg_temp:.1f}Â°C\")\n",
    "\n",
    "# 2. Count\n",
    "reading_counts = grouped.size()\n",
    "print(\"\\nReading Counts by Station:\")\n",
    "for station, count in reading_counts.items():\n",
    "    print(f\"  {station}: {count} readings\")\n",
    "\n",
    "# 3. Multiple columns at once\n",
    "multi_stats = grouped[['temperature_c', 'humidity_percent']].mean()\n",
    "print(\"\\nAverage Temperature and Humidity:\")\n",
    "print(multi_stats.round(1))\n",
    "\n",
    "# 4. Multiple functions at once\n",
    "detailed_stats = grouped['temperature_c'].agg(['mean', 'min', 'max', 'std', 'count'])\n",
    "print(\"\\nDetailed Temperature Statistics:\")\n",
    "print(detailed_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating Summary DataFrames\n",
    "\n",
    "The key skill is combining multiple aggregations into a clean summary DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Step by step aggregation\n",
    "print(\"=== CREATING SUMMARY DATAFRAME ===\")\n",
    "\n",
    "grouped = environmental_data.groupby('station_id')\n",
    "\n",
    "# Calculate each statistic separately\n",
    "avg_temp = grouped['temperature_c'].mean().round(1)\n",
    "avg_humidity = grouped['humidity_percent'].mean().round(1)\n",
    "reading_count = grouped.size()\n",
    "\n",
    "# Combine into a DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'station_id': avg_temp.index,\n",
    "    'avg_temperature': avg_temp.values,\n",
    "    'avg_humidity': avg_humidity.values,\n",
    "    'reading_count': reading_count.values\n",
    "})\n",
    "\n",
    "print(\"Summary DataFrame:\")\n",
    "print(summary_df)\n",
    "\n",
    "# Find temperature extremes\n",
    "hottest_station = summary_df.loc[summary_df['avg_temperature'].idxmax()]\n",
    "coolest_station = summary_df.loc[summary_df['avg_temperature'].idxmin()]\n",
    "\n",
    "print(f\"\\nHottest station: {hottest_station['station_id']} (avg: {hottest_station['avg_temperature']:.1f}Â°C)\")\n",
    "print(f\"Coolest station: {coolest_station['station_id']} (avg: {coolest_station['avg_temperature']:.1f}Â°C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Visualizing the Results\n",
    "\n",
    "Let's create visualizations to better understand our station statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations of station statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Average Temperature by Station\n",
    "axes[0, 0].bar(summary_df['station_id'], summary_df['avg_temperature'], color='red', alpha=0.7)\n",
    "axes[0, 0].set_title('Average Temperature by Station')\n",
    "axes[0, 0].set_ylabel('Temperature (Â°C)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(summary_df['avg_temperature']):\n",
    "    axes[0, 0].text(i, v + 0.5, f'{v:.1f}Â°C', ha='center')\n",
    "\n",
    "# 2. Average Humidity by Station\n",
    "axes[0, 1].bar(summary_df['station_id'], summary_df['avg_humidity'], color='blue', alpha=0.7)\n",
    "axes[0, 1].set_title('Average Humidity by Station')\n",
    "axes[0, 1].set_ylabel('Humidity (%)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(summary_df['avg_humidity']):\n",
    "    axes[0, 1].text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "\n",
    "# 3. Reading Count by Station\n",
    "axes[1, 0].bar(summary_df['station_id'], summary_df['reading_count'], color='green', alpha=0.7)\n",
    "axes[1, 0].set_title('Number of Readings by Station')\n",
    "axes[1, 0].set_ylabel('Reading Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(summary_df['reading_count']):\n",
    "    axes[1, 0].text(i, v + 5, f'{v}', ha='center')\n",
    "\n",
    "# 4. Temperature vs Humidity Relationship\n",
    "scatter = axes[1, 1].scatter(summary_df['avg_temperature'], summary_df['avg_humidity'], \n",
    "                           s=summary_df['reading_count']/3, alpha=0.7, c=range(len(summary_df)), cmap='viridis')\n",
    "axes[1, 1].set_title('Temperature vs Humidity by Station')\n",
    "axes[1, 1].set_xlabel('Average Temperature (Â°C)')\n",
    "axes[1, 1].set_ylabel('Average Humidity (%)')\n",
    "\n",
    "# Add station labels\n",
    "for i, row in summary_df.iterrows():\n",
    "    axes[1, 1].annotate(row['station_id'], (row['avg_temperature'], row['avg_humidity']), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary insights\n",
    "print(\"\\n=== DATA INSIGHTS ===\")\n",
    "print(f\"Temperature-humidity correlation: {summary_df['avg_temperature'].corr(summary_df['avg_humidity']):.3f}\")\n",
    "print(f\"Most data: {summary_df.loc[summary_df['reading_count'].idxmax(), 'station_id']} ({summary_df['reading_count'].max()} readings)\")\n",
    "print(f\"Least data: {summary_df.loc[summary_df['reading_count'].idxmin(), 'station_id']} ({summary_df['reading_count'].min()} readings)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Complete Function\n",
    "\n",
    "### 3.1 Function Implementation Example\n",
    "\n",
    "Now let's build the complete function that matches the requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_station_statistics_example(df):\n",
    "    \"\"\"Example implementation of the calculate_station_statistics function.\"\"\"\n",
    "    \n",
    "    # Print header\n",
    "    print(\"=\" * 50)\n",
    "    print(\"CALCULATING STATION STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Input validation\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"Error: DataFrame is empty or None\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_columns = ['station_id', 'temperature_c', 'humidity_percent']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"Error: Missing required columns: {missing_columns}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Print input data summary\n",
    "    print(f\"Processing {len(df):,} temperature readings...\")\n",
    "    \n",
    "    # Get unique stations\n",
    "    unique_stations = df['station_id'].unique()\n",
    "    print(f\"Found {len(unique_stations)} weather stations: {list(unique_stations)}\")\n",
    "    \n",
    "    # Group data by station\n",
    "    grouped = df.groupby('station_id')\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_temperature = grouped['temperature_c'].mean().round(1)\n",
    "    avg_humidity = grouped['humidity_percent'].mean().round(1)\n",
    "    reading_count = grouped.size()\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary = pd.DataFrame({\n",
    "        'station_id': avg_temperature.index,\n",
    "        'avg_temperature': avg_temperature.values,\n",
    "        'avg_humidity': avg_humidity.values,\n",
    "        'reading_count': reading_count.values\n",
    "    })\n",
    "    \n",
    "    # Reset index to make station_id a regular column\n",
    "    summary = summary.reset_index(drop=True)\n",
    "    \n",
    "    # Print summary of results\n",
    "    print(f\"\\nTemperature range across all stations: {summary['avg_temperature'].min():.1f}Â°C to {summary['avg_temperature'].max():.1f}Â°C\")\n",
    "    print(f\"Humidity range across all stations: {summary['avg_humidity'].min():.1f}% to {summary['avg_humidity'].max():.1f}%\")\n",
    "    print(f\"Total readings processed: {summary['reading_count'].sum():,}\")\n",
    "    print(f\"Average readings per station: {summary['reading_count'].mean():.0f}\")\n",
    "    \n",
    "    # Find temperature extremes\n",
    "    hottest_station = summary.loc[summary['avg_temperature'].idxmax()]\n",
    "    coolest_station = summary.loc[summary['avg_temperature'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nHottest station: {hottest_station['station_id']} (avg: {hottest_station['avg_temperature']:.1f}Â°C)\")\n",
    "    print(f\"Coolest station: {coolest_station['station_id']} (avg: {coolest_station['avg_temperature']:.1f}Â°C)\")\n",
    "    \n",
    "    print(\"\\nStation statistics calculated successfully!\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Test the function\n",
    "station_stats = calculate_station_statistics_example(environmental_data)\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "print(station_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Your Implementation Task\n",
    "\n",
    "### 4.1 Implementation Guidelines\n",
    "\n",
    "Now implement this function in `src/pandas_basics.py`. Here are the key steps:\n",
    "\n",
    "```python\n",
    "def calculate_station_statistics(df):\n",
    "    # TODO: Print header with function name\n",
    "    # TODO: Validate input DataFrame (check if None or empty)\n",
    "    # TODO: Check for required columns: ['station_id', 'temperature_c', 'humidity_percent']\n",
    "    # TODO: Print summary of input data\n",
    "    # TODO: Get unique stations and report count\n",
    "    # TODO: Group data by station_id using df.groupby('station_id')\n",
    "    # TODO: Calculate avg_temperature using .mean().round(1)\n",
    "    # TODO: Calculate avg_humidity using .mean().round(1) \n",
    "    # TODO: Count readings per station using .size()\n",
    "    # TODO: Create summary DataFrame with all statistics\n",
    "    # TODO: Reset index to make station_id a regular column\n",
    "    # TODO: Print summary statistics (ranges, totals)\n",
    "    # TODO: Find and report hottest/coolest stations\n",
    "    # TODO: Return the summary DataFrame\n",
    "```\n",
    "\n",
    "### 4.2 Testing Your Implementation\n",
    "\n",
    "Test your function with:\n",
    "\n",
    "```bash\n",
    "uv run pytest tests/test_pandas_basics.py::test_calculate_station_statistics -v\n",
    "```\n",
    "\n",
    "### 4.3 Expected Output Format\n",
    "\n",
    "Your function should return a DataFrame with exactly these columns:\n",
    "- `station_id`: Station identifier (string)\n",
    "- `avg_temperature`: Average temperature rounded to 1 decimal (float)\n",
    "- `avg_humidity`: Average humidity rounded to 1 decimal (float) \n",
    "- `reading_count`: Number of readings for this station (int)\n",
    "\n",
    "### 4.4 Common Issues and Solutions\n",
    "\n",
    "**Issue 1: Index problems**\n",
    "```python\n",
    "# Wrong: station_id becomes the index\n",
    "summary = grouped_data.mean()\n",
    "\n",
    "# Right: station_id remains a regular column\n",
    "summary = grouped_data.mean().reset_index()\n",
    "```\n",
    "\n",
    "**Issue 2: Column naming**\n",
    "```python\n",
    "# Make sure your final DataFrame has exactly these column names:\n",
    "['station_id', 'avg_temperature', 'avg_humidity', 'reading_count']\n",
    "```\n",
    "\n",
    "**Issue 3: Rounding**\n",
    "```python\n",
    "# Remember to round temperature and humidity to 1 decimal place\n",
    "avg_temperature = grouped['temperature_c'].mean().round(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Summary and Next Steps\n",
    "\n",
    "### What You've Learned\n",
    "- How to group data using `.groupby()`\n",
    "- Computing aggregate statistics (mean, count, min, max)\n",
    "- Creating summary DataFrames from grouped data\n",
    "- Finding extreme values and patterns in data\n",
    "- Professional data reporting and validation\n",
    "\n",
    "### Your Implementation Checklist\n",
    "- [ ] Print informative headers and progress messages\n",
    "- [ ] Validate input data and handle errors gracefully\n",
    "- [ ] Check for required columns before processing\n",
    "- [ ] Use `.groupby()` to group data by station\n",
    "- [ ] Calculate mean temperature and humidity (rounded to 1 decimal)\n",
    "- [ ] Count readings per station using `.size()`\n",
    "- [ ] Create DataFrame with exact column names expected by tests\n",
    "- [ ] Reset index to make station_id a regular column\n",
    "- [ ] Report summary statistics and extremes\n",
    "- [ ] Return properly formatted DataFrame\n",
    "\n",
    "### Next Function\n",
    "Once you've implemented and tested this function, move on to:\n",
    "**[`04_function_join_station_data.ipynb`](04_function_join_station_data.ipynb)**\n",
    "\n",
    "Where you'll learn to combine datasets using pandas merge operations!\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Data aggregation is one of the most powerful features of pandas - it transforms raw data into actionable insights! ðŸ“Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
