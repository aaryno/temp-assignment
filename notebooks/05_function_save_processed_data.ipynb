{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ Function 5: Save Processed Data\n",
    "\n",
    "## Building the `save_processed_data` Function\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand data export and file I/O operations in pandas\n",
    "- Learn to save DataFrames to CSV files\n",
    "- Master file path handling and directory management\n",
    "- Implement data validation before saving\n",
    "- Handle file permissions and error scenarios\n",
    "\n",
    "**Professional Context:**\n",
    "Data saving is crucial for:\n",
    "- **Workflow persistence** - Save intermediate results for later analysis\n",
    "- **Data sharing** - Export data for colleagues and stakeholders\n",
    "- **Integration** - Prepare data for other software (QGIS, Excel, databases)\n",
    "- **Backup and archival** - Preserve processed datasets for future reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Data Export\n",
    "\n",
    "### 1.1 Why Save Processed Data?\n",
    "\n",
    "**Data processing workflows** often involve multiple steps:\n",
    "1. Load raw data\n",
    "2. Clean and filter data  \n",
    "3. Calculate statistics and derive new variables\n",
    "4. Join with additional datasets\n",
    "5. **Save processed results** ‚Üê This function!\n",
    "\n",
    "**Benefits of saving processed data:**\n",
    "- **Time saving**: Don't re-process large datasets every time\n",
    "- **Sharing**: Send clean data to colleagues or clients\n",
    "- **Integration**: Import into GIS software, spreadsheets, or databases\n",
    "- **Documentation**: Keep records of analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Create sample processed data\n",
    "processed_data = pd.DataFrame({\n",
    "    'station_id': ['STN_001', 'STN_002', 'STN_003', 'STN_004', 'STN_005'],\n",
    "    'station_name': ['Downtown', 'Coastal', 'Mountain', 'Airport', 'University'],\n",
    "    'avg_temperature': [22.3, 19.1, 16.8, 24.7, 21.2],\n",
    "    'avg_humidity': [64.2, 76.8, 81.3, 57.9, 68.5],\n",
    "    'reading_count': [245, 198, 267, 189, 223],\n",
    "    'latitude': [40.123, 40.789, 41.234, 40.678, 40.876],\n",
    "    'longitude': [-74.456, -73.987, -74.567, -74.123, -73.876]\n",
    "})\n",
    "\n",
    "print(\"Sample Processed Data:\")\n",
    "print(processed_data)\n",
    "print(f\"\\nData shape: {processed_data.shape}\")\n",
    "print(f\"Columns: {list(processed_data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Data Export Operations\n",
    "\n",
    "### 2.1 Saving to CSV Files\n",
    "\n",
    "CSV is the most common format for sharing tabular data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "# Basic CSV export\n",
    "csv_path = output_dir / 'station_summary.csv'\n",
    "processed_data.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\nSaved data to: {csv_path}\")\n",
    "print(f\"File exists: {csv_path.exists()}\")\n",
    "print(f\"File size: {csv_path.stat().st_size} bytes\")\n",
    "\n",
    "# Verify by reading back\n",
    "loaded_data = pd.read_csv(csv_path)\n",
    "print(f\"\\nVerification - loaded {len(loaded_data)} rows\")\n",
    "print(\"First few rows:\")\n",
    "print(loaded_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Professional File Organization\n",
    "\n",
    "Professional workflows require organized file structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create organized directory structure\n",
    "base_dir = Path('environmental_analysis')\n",
    "summaries_dir = base_dir / 'summaries'\n",
    "raw_data_dir = base_dir / 'processed_readings'\n",
    "\n",
    "# Create directories\n",
    "for directory in [base_dir, summaries_dir, raw_data_dir]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created: {directory}\")\n",
    "\n",
    "# Professional file naming with timestamps\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "date_only = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Save with descriptive filename\n",
    "filename = f\"station_summary_{date_only}.csv\"\n",
    "file_path = summaries_dir / filename\n",
    "\n",
    "processed_data.to_csv(file_path, index=False, float_format='%.2f')\n",
    "print(f\"\\nSaved to: {file_path}\")\n",
    "print(f\"Filename pattern: [description]_[date].csv\")\n",
    "\n",
    "# List directory contents\n",
    "print(f\"\\nContents of {summaries_dir}:\")\n",
    "for item in summaries_dir.iterdir():\n",
    "    print(f\"  {item.name} ({item.stat().st_size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Validation Before Saving\n",
    "\n",
    "Always validate data before saving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data_before_save(df, data_name=\"DataFrame\"):\n",
    "    \"\"\"Validate data before saving.\"\"\"\n",
    "    \n",
    "    print(f\"=== VALIDATING {data_name.upper()} ===\")\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    # Check basic structure\n",
    "    if df is None:\n",
    "        issues.append(\"DataFrame is None\")\n",
    "        return False, issues\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        issues.append(\"DataFrame is empty\")\n",
    "        return False, issues\n",
    "    \n",
    "    if len(df.columns) == 0:\n",
    "        issues.append(\"DataFrame has no columns\")\n",
    "        return False, issues\n",
    "    \n",
    "    print(f\"‚úì Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    \n",
    "    # Check for missing data\n",
    "    missing_count = df.isnull().sum().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_percent = (missing_count / (df.shape[0] * df.shape[1])) * 100\n",
    "        print(f\"‚ö†Ô∏è  Missing data: {missing_count} values ({missing_percent:.1f}%)\")\n",
    "        if missing_percent > 50:\n",
    "            issues.append(f\"High missing data: {missing_percent:.1f}%\")\n",
    "    else:\n",
    "        print(\"‚úì No missing values\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"‚ö†Ô∏è  Duplicate rows: {duplicate_count}\")\n",
    "    else:\n",
    "        print(\"‚úì No duplicate rows\")\n",
    "    \n",
    "    is_valid = len(issues) == 0\n",
    "    status = \"VALID\" if is_valid else \"INVALID\"\n",
    "    print(f\"\\nValidation result: {status}\")\n",
    "    \n",
    "    return is_valid, issues\n",
    "\n",
    "# Test validation\n",
    "is_valid, issues = validate_data_before_save(processed_data, \"Station Summary\")\n",
    "\n",
    "if not is_valid:\n",
    "    print(\"\\nISSUES FOUND:\")\n",
    "    for issue in issues:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Data is ready for saving!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Complete Function\n",
    "\n",
    "### 3.1 Complete Function Implementation\n",
    "\n",
    "Now let's build the complete function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data_example(df, file_path):\n",
    "    \"\"\"Example implementation of save_processed_data function.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"SAVING PROCESSED DATA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Input validation\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"Error: DataFrame is empty or None\")\n",
    "        return False\n",
    "    \n",
    "    if not file_path or str(file_path).strip() == \"\":\n",
    "        print(\"Error: Invalid file path\")\n",
    "        return False\n",
    "    \n",
    "    # Convert to Path object for better handling\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    print(f\"Data to save: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"Target file: {file_path}\")\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Directory: {file_path.parent}\")\n",
    "    \n",
    "    # Validate data quality\n",
    "    missing_count = df.isnull().sum().sum()\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    \n",
    "    print(f\"Data quality check:\")\n",
    "    print(f\"  Missing values: {missing_count}\")\n",
    "    print(f\"  Duplicate rows: {duplicate_count}\")\n",
    "    \n",
    "    try:\n",
    "        # Save the file\n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "        # Verify the save\n",
    "        if file_path.exists():\n",
    "            file_size = file_path.stat().st_size\n",
    "            \n",
    "            # Quick verification by reading back\n",
    "            verification_df = pd.read_csv(file_path)\n",
    "            \n",
    "            print(f\"\\n‚úÖ File saved successfully!\")\n",
    "            print(f\"File size: {file_size:,} bytes\")\n",
    "            print(f\"Verification: {len(verification_df)} rows loaded\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\n‚ùå Error: File was not created\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error saving file: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Test the function\n",
    "test_path = 'output/test_station_data.csv'\n",
    "success = save_processed_data_example(processed_data, test_path)\n",
    "print(f\"\\nSave operation success: {success}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Error Handling Examples\n",
    "\n",
    "Test the function with various error conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ERROR HANDLING TESTS ===\")\n",
    "\n",
    "# Test 1: Empty DataFrame\n",
    "print(\"\\n1. Testing with empty DataFrame:\")\n",
    "empty_df = pd.DataFrame()\n",
    "result1 = save_processed_data_example(empty_df, 'output/empty_test.csv')\n",
    "print(f\"Result: {result1}\")\n",
    "\n",
    "# Test 2: Invalid file path\n",
    "print(\"\\n2. Testing with invalid file path:\")\n",
    "result2 = save_processed_data_example(processed_data, '')\n",
    "print(f\"Result: {result2}\")\n",
    "\n",
    "# Test 3: Valid data and path\n",
    "print(\"\\n3. Testing with valid data and path:\")\n",
    "result3 = save_processed_data_example(processed_data, 'output/valid_test.csv')\n",
    "print(f\"Result: {result3}\")\n",
    "\n",
    "print(\"\\n=== ERROR HANDLING COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Your Implementation Task\n",
    "\n",
    "### 4.1 Implementation Guidelines\n",
    "\n",
    "Now implement this function in `src/pandas_basics.py`:\n",
    "\n",
    "```python\n",
    "def save_processed_data(df, file_path):\n",
    "    # TODO: Print header\n",
    "    # TODO: Validate input DataFrame (not None or empty)\n",
    "    # TODO: Validate file path (not empty or None)\n",
    "    # TODO: Convert file_path to Path object\n",
    "    # TODO: Print data summary (shape, target file)\n",
    "    # TODO: Create parent directory if needed\n",
    "    # TODO: Validate data quality (check missing values, duplicates)\n",
    "    # TODO: Save DataFrame to CSV using to_csv()\n",
    "    # TODO: Verify file was created and get file size\n",
    "    # TODO: Print success message with file details\n",
    "    # TODO: Handle exceptions and return True/False\n",
    "```\n",
    "\n",
    "### 4.2 Testing Your Implementation\n",
    "\n",
    "```bash\n",
    "uv run pytest tests/test_pandas_basics.py::test_save_processed_data -v\n",
    "```\n",
    "\n",
    "### 4.3 Key Requirements\n",
    "\n",
    "- Save DataFrame to CSV format without index\n",
    "- Create output directory if it doesn't exist\n",
    "- Validate input data and file path\n",
    "- Return True if successful, False if failed\n",
    "- Provide informative progress messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary and Next Steps\n",
    "\n",
    "### What You've Learned\n",
    "- How to save DataFrames to CSV files using `.to_csv()`\n",
    "- Professional file organization and naming conventions\n",
    "- Data validation before saving to prevent errors\n",
    "- Error handling for file I/O operations\n",
    "- Directory management with Path objects\n",
    "\n",
    "### Your Implementation Checklist\n",
    "- [ ] Validate DataFrame input (not None or empty)\n",
    "- [ ] Validate file path parameter\n",
    "- [ ] Create parent directories as needed\n",
    "- [ ] Check data quality before saving\n",
    "- [ ] Save to CSV without index\n",
    "- [ ] Verify file was created successfully\n",
    "- [ ] Handle exceptions gracefully\n",
    "- [ ] Return success/failure status\n",
    "\n",
    "### Assignment Complete!\n",
    "Once you've implemented and tested this function, you'll have completed all 5 pandas functions:\n",
    "\n",
    "1. ‚úÖ Load and explore data\n",
    "2. ‚úÖ Filter environmental data  \n",
    "3. ‚úÖ Calculate station statistics\n",
    "4. ‚úÖ Join station data\n",
    "5. ‚úÖ Save processed data\n",
    "\n",
    "**Congratulations!** You've mastered the essential pandas skills for GIS data analysis!\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Saving your work is just as important as doing the analysis - make sure your hard work is preserved! üíæ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
