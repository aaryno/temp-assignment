{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function 9: Analyze Temporal Patterns ğŸ“ˆ\n",
        "\n",
        "**ğŸ¤– AI-Enhanced Learning: Time Series Analysis with Pandas**\n",
        "\n",
        "In this notebook, you'll learn how to build the `analyze_temporal_patterns()` function using AI assistance. This function analyzes temporal patterns in environmental data, calculating trends, seasonal patterns, and statistical summaries over time periods.\n",
        "\n",
        "## ğŸ¯ What This Function Does\n",
        "- Converts date columns to pandas datetime objects\n",
        "- Calculates temporal trends and seasonal patterns\n",
        "- Performs time-based grouping and resampling\n",
        "- Identifies patterns across multiple time scales\n",
        "- Generates comprehensive temporal analysis reports\n",
        "\n",
        "## ğŸ¤– AI Learning Objectives\n",
        "By the end of this notebook, you will:\n",
        "1. **Use Copilot CHAT** to understand pandas datetime functionality\n",
        "2. **Use AGENT mode** to implement groupby operations and time resampling\n",
        "3. **Use EDIT mode** to add trend analysis and statistical calculations\n",
        "4. **Learn about** datetime indexing, time series analysis, and temporal aggregation\n",
        "\n",
        "## ğŸ”§ Function Signature\n",
        "```python\n",
        "def analyze_temporal_patterns(df, date_column='date', value_column='temperature', \n",
        "                            groupby_column='station_id'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        df (pandas.DataFrame): Environmental data with datetime information\n",
        "        date_column (str): Name of date/datetime column\n",
        "        value_column (str): Name of value column to analyze over time\n",
        "        groupby_column (str): Column to group by for pattern analysis\n",
        "    \n",
        "    Returns:\n",
        "        dict: Temporal analysis results with trends, patterns, and statistics\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "## ğŸš€ Let's Discover Time Patterns!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Step 1: Import Libraries and Prepare Data\n",
        "\n",
        "Let's start by importing pandas and preparing time series data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(f\"âœ… Pandas version: {pd.__version__}\")\n",
        "\n",
        "# Load our environmental data\n",
        "df = pd.read_csv('../data/temperature_readings.csv')\n",
        "\n",
        "# Create sample temporal data if date column doesn't exist\n",
        "if 'date' not in df.columns:\n",
        "    # Create a range of dates for demonstration\n",
        "    start_date = datetime(2023, 1, 1)\n",
        "    dates = [start_date + timedelta(days=i) for i in range(len(df))]\n",
        "    df['date'] = dates\n",
        "    print(\"ğŸ“… Created sample date column for temporal analysis\")\n",
        "\n",
        "print(f\"ğŸ“Š Data shape: {df.shape}\")\n",
        "print(f\"ğŸ—“ï¸  Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "print(f\"ğŸ“ˆ Sample data with dates:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“… Step 2: Understanding Pandas Datetime Operations\n",
        "\n",
        "**Temporal pattern analysis** is crucial for environmental data because:\n",
        "\n",
        "- **Seasonal patterns**: Temperature varies by month/season\n",
        "- **Daily cycles**: Weather patterns change throughout the day\n",
        "- **Long-term trends**: Climate change over years\n",
        "- **Anomaly detection**: Unusual weather events\n",
        "\n",
        "### ğŸ•°ï¸ **Key Pandas Datetime Functions:**\n",
        "\n",
        "1. **`pd.to_datetime()`**: Convert strings to datetime objects\n",
        "2. **`.dt.hour/.dt.month/.dt.year`**: Extract time components\n",
        "3. **`.groupby(df['date'].dt.month)`**: Group by time periods\n",
        "4. **`.resample()`**: Aggregate data over time periods  \n",
        "5. **`.rolling()`**: Calculate moving averages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Convert date column to datetime and explore temporal components\n",
        "print(\"ğŸ“… Converting date column to pandas datetime\")\n",
        "\n",
        "# Convert date column to datetime if it's not already\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Extract temporal components\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "df['day'] = df['date'].dt.day\n",
        "df['weekday'] = df['date'].dt.day_name()\n",
        "\n",
        "print(f\"âœ… Date conversion complete!\")\n",
        "print(f\"ğŸ“Š Data types:\")\n",
        "print(df[['date', 'year', 'month', 'day', 'weekday', 'temperature']].dtypes)\n",
        "\n",
        "print(f\"\\nğŸ—“ï¸ Temporal components sample:\")\n",
        "print(df[['date', 'year', 'month', 'day', 'weekday', 'temperature']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Step 4: Analyzing Temporal Patterns\n",
        "\n",
        "Let's analyze different types of temporal patterns in our environmental data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Monthly patterns - seasonal analysis\n",
        "print(\"ğŸŒ… Analyzing monthly temperature patterns\")\n",
        "\n",
        "monthly_stats = df.groupby('month')['temperature'].agg(['mean', 'min', 'max', 'count'])\n",
        "monthly_stats['month_name'] = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'][:len(monthly_stats)]\n",
        "\n",
        "print(\"ğŸ“Š Monthly temperature statistics:\")\n",
        "print(monthly_stats)\n",
        "\n",
        "# Find warmest and coolest months\n",
        "warmest_month = monthly_stats['mean'].idxmax()\n",
        "coolest_month = monthly_stats['mean'].idxmin()\n",
        "\n",
        "print(f\"\\nğŸ”¥ Warmest month: {warmest_month} ({monthly_stats.loc[warmest_month, 'mean']:.1f}Â°C average)\")\n",
        "print(f\"â„ï¸  Coolest month: {coolest_month} ({monthly_stats.loc[coolest_month, 'mean']:.1f}Â°C average)\")\n",
        "print(f\"ğŸŒ¡ï¸  Temperature range: {monthly_stats['mean'].max() - monthly_stats['mean'].min():.1f}Â°C\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Building the Complete Temporal Analysis Function\n",
        "def analyze_temporal_patterns(df, date_column='date', value_column='temperature', groupby_column='station_id'):\n",
        "    \"\"\"\n",
        "    Analyze temporal patterns in environmental data.\n",
        "    \n",
        "    Args:\n",
        "        df (pandas.DataFrame): Environmental data with datetime information\n",
        "        date_column (str): Name of date/datetime column\n",
        "        value_column (str): Name of value column to analyze over time  \n",
        "        groupby_column (str): Column to group by for pattern analysis\n",
        "    \n",
        "    Returns:\n",
        "        dict: Temporal analysis results with trends, patterns, and statistics\n",
        "    \"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"ANALYZING TEMPORAL PATTERNS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Validate inputs\n",
        "    if date_column not in df.columns:\n",
        "        print(f\"âŒ Error: Date column '{date_column}' not found\")\n",
        "        return {}\n",
        "        \n",
        "    if value_column not in df.columns:\n",
        "        print(f\"âŒ Error: Value column '{value_column}' not found\")\n",
        "        return {}\n",
        "    \n",
        "    # Make a copy and ensure date column is datetime\n",
        "    analysis_df = df.copy()\n",
        "    analysis_df[date_column] = pd.to_datetime(analysis_df[date_column])\n",
        "    \n",
        "    print(f\"ğŸ“… Date range: {analysis_df[date_column].min()} to {analysis_df[date_column].max()}\")\n",
        "    print(f\"ğŸ“Š Analyzing {len(analysis_df)} records\")\n",
        "    \n",
        "    # Extract temporal components\n",
        "    analysis_df['year'] = analysis_df[date_column].dt.year\n",
        "    analysis_df['month'] = analysis_df[date_column].dt.month\n",
        "    analysis_df['day_of_week'] = analysis_df[date_column].dt.dayofweek\n",
        "    analysis_df['day_name'] = analysis_df[date_column].dt.day_name()\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    # 1. Overall statistics\n",
        "    results['overall_stats'] = {\n",
        "        'mean': analysis_df[value_column].mean(),\n",
        "        'min': analysis_df[value_column].min(),\n",
        "        'max': analysis_df[value_column].max(),\n",
        "        'std': analysis_df[value_column].std(),\n",
        "        'count': len(analysis_df)\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nğŸ“ˆ Overall {value_column} statistics:\")\n",
        "    print(f\"   Mean: {results['overall_stats']['mean']:.2f}\")\n",
        "    print(f\"   Range: {results['overall_stats']['min']:.2f} to {results['overall_stats']['max']:.2f}\")\n",
        "    print(f\"   Std Dev: {results['overall_stats']['std']:.2f}\")\n",
        "    \n",
        "    # 2. Monthly patterns\n",
        "    monthly_patterns = analysis_df.groupby('month')[value_column].agg(['mean', 'min', 'max', 'count'])\n",
        "    results['monthly_patterns'] = monthly_patterns.to_dict('index')\n",
        "    \n",
        "    warmest_month = monthly_patterns['mean'].idxmax()\n",
        "    coolest_month = monthly_patterns['mean'].idxmin()\n",
        "    \n",
        "    results['seasonal_summary'] = {\n",
        "        'warmest_month': int(warmest_month),\n",
        "        'warmest_temp': float(monthly_patterns.loc[warmest_month, 'mean']),\n",
        "        'coolest_month': int(coolest_month),\n",
        "        'coolest_temp': float(monthly_patterns.loc[coolest_month, 'mean']),\n",
        "        'seasonal_range': float(monthly_patterns['mean'].max() - monthly_patterns['mean'].min())\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nğŸŒ… Seasonal patterns:\")\n",
        "    print(f\"   Warmest month: {warmest_month} ({results['seasonal_summary']['warmest_temp']:.1f}Â°C)\")\n",
        "    print(f\"   Coolest month: {coolest_month} ({results['seasonal_summary']['coolest_temp']:.1f}Â°C)\")\n",
        "    print(f\"   Seasonal range: {results['seasonal_summary']['seasonal_range']:.1f}Â°C\")\n",
        "    \n",
        "    # 3. Day of week patterns\n",
        "    if len(analysis_df['day_of_week'].unique()) > 1:\n",
        "        dow_patterns = analysis_df.groupby(['day_of_week', 'day_name'])[value_column].mean().reset_index()\n",
        "        results['day_of_week_patterns'] = dow_patterns.to_dict('records')\n",
        "        \n",
        "        print(f\"\\nğŸ“… Day of week patterns:\")\n",
        "        for _, row in dow_patterns.iterrows():\n",
        "            print(f\"   {row['day_name']}: {row[value_column]:.2f}\")\n",
        "    \n",
        "    # 4. Station-specific patterns (if groupby column exists and has multiple values)\n",
        "    if (groupby_column in analysis_df.columns and \n",
        "        analysis_df[groupby_column].nunique() > 1):\n",
        "        \n",
        "        station_patterns = analysis_df.groupby(groupby_column)[value_column].agg(['mean', 'min', 'max', 'count'])\n",
        "        results['station_patterns'] = station_patterns.to_dict('index')\n",
        "        \n",
        "        # Find stations with extreme values\n",
        "        hottest_station = station_patterns['mean'].idxmax()\n",
        "        coolest_station = station_patterns['mean'].idxmin()\n",
        "        \n",
        "        results['station_summary'] = {\n",
        "            'hottest_station': str(hottest_station),\n",
        "            'hottest_temp': float(station_patterns.loc[hottest_station, 'mean']),\n",
        "            'coolest_station': str(coolest_station),\n",
        "            'coolest_temp': float(station_patterns.loc[coolest_station, 'mean'])\n",
        "        }\n",
        "        \n",
        "        print(f\"\\nğŸŒ¡ï¸  Station patterns:\")\n",
        "        print(f\"   Hottest station: {hottest_station} ({results['station_summary']['hottest_temp']:.1f}Â°C)\")\n",
        "        print(f\"   Coolest station: {coolest_station} ({results['station_summary']['coolest_temp']:.1f}Â°C)\")\n",
        "    \n",
        "    # 5. Temporal trends (if multiple years)\n",
        "    unique_years = analysis_df['year'].unique()\n",
        "    if len(unique_years) > 1:\n",
        "        yearly_trends = analysis_df.groupby('year')[value_column].mean()\n",
        "        results['yearly_trends'] = yearly_trends.to_dict()\n",
        "        \n",
        "        # Calculate trend direction\n",
        "        first_year_avg = yearly_trends.iloc[0]\n",
        "        last_year_avg = yearly_trends.iloc[-1]\n",
        "        trend_change = last_year_avg - first_year_avg\n",
        "        \n",
        "        results['trend_analysis'] = {\n",
        "            'first_year': int(yearly_trends.index[0]),\n",
        "            'last_year': int(yearly_trends.index[-1]),\n",
        "            'first_year_avg': float(first_year_avg),\n",
        "            'last_year_avg': float(last_year_avg),\n",
        "            'total_change': float(trend_change),\n",
        "            'trend_direction': 'warming' if trend_change > 0 else 'cooling'\n",
        "        }\n",
        "        \n",
        "        print(f\"\\nğŸ“Š Long-term trends:\")\n",
        "        print(f\"   {yearly_trends.index[0]}: {first_year_avg:.2f}Â°C\")\n",
        "        print(f\"   {yearly_trends.index[-1]}: {last_year_avg:.2f}Â°C\")\n",
        "        print(f\"   Change: {trend_change:+.2f}Â°C ({results['trend_analysis']['trend_direction']})\")\n",
        "    \n",
        "    print(f\"\\nâœ… Temporal analysis complete!\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test the function\n",
        "print(\"ğŸ§ª Testing temporal analysis function:\")\n",
        "temporal_results = analyze_temporal_patterns(df, 'date', 'temperature', 'station_id')\n",
        "\n",
        "print(f\"\\nğŸ“‹ Results summary:\")\n",
        "print(f\"Number of analysis categories: {len(temporal_results)}\")\n",
        "for key in temporal_results.keys():\n",
        "    print(f\"  - {key}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ **Your Assignment Task**\n",
        "\n",
        "### **âœ… STEP-BY-STEP INSTRUCTIONS:**\n",
        "\n",
        "#### **1. COPY YOUR WORKING FUNCTION**\n",
        "- **FROM**: The complete function in the cell above\n",
        "- **TO**: `src/pandas_basics.py` \n",
        "- **REPLACE**: All the TODO comments in the `analyze_temporal_patterns()` function\n",
        "\n",
        "#### **2. TEST YOUR IMPLEMENTATION:**\n",
        "```bash\n",
        "# Test just this function\n",
        "uv run pytest tests/test_pandas_basics.py::test_analyze_temporal_patterns -v\n",
        "```\n",
        "\n",
        "#### **3. âš ï¸ COMMON MISTAKES TO AVOID:**\n",
        "- âŒ **Forgetting `pd.to_datetime()`** for date conversion\n",
        "- âŒ **Not handling missing columns** gracefully\n",
        "- âŒ **Accessing `.dt` on non-datetime columns** (causes errors)\n",
        "- âœ… **Do validate data types** before datetime operations\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”‘ Key Learning Points\n",
        "\n",
        "- **`pd.to_datetime()`** converts strings to datetime objects for temporal analysis\n",
        "- **`.dt.year/.dt.month`** extracts specific time components from datetime columns\n",
        "- **Temporal grouping** reveals seasonal patterns and trends in environmental data\n",
        "- **Multiple time scales** (yearly, monthly, daily) show different patterns\n",
        "- **Trend analysis** identifies long-term changes in data over time\n",
        "- **Dictionary results** organize complex analysis results for easy access\n",
        "\n",
        "## ğŸš€ Congratulations!\n",
        "\n",
        "You've completed all **8 functions** in the pandas assignment! ğŸ‰\n",
        "\n",
        "**Final steps:**\n",
        "1. **Test all functions**: `uv run pytest tests/ -v`\n",
        "2. **Complete your reflection**: Write `AI_LEARNING_REFLECTION.md` \n",
        "3. **Submit your assignment**: Push to your repository\n",
        "\n",
        "**Remember: You've learned professional-grade pandas skills that are used daily by environmental scientists, GIS professionals, and data analysts worldwide! ğŸŒğŸ“Š**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
