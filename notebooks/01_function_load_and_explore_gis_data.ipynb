{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function 1: Load and Explore GIS Data 📊\n",
    "\n",
    "**Welcome to your first pandas function!**\n",
    "\n",
    "In this notebook, you'll learn how to build the `load_and_explore_gis_data()` function step by step. This is like opening a spreadsheet file and getting familiar with what's inside.\n",
    "\n",
    "## 🎯 What This Function Does\n",
    "- Loads a CSV file into a pandas DataFrame\n",
    "- Shows you key information about the dataset\n",
    "- Displays the first few rows so you can see what the data looks like\n",
    "- Provides summary statistics\n",
    "- Handles errors gracefully\n",
    "\n",
    "## 🔧 Function Signature\n",
    "```python\n",
    "def load_and_explore_gis_data(file_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        file_path (str): Path to CSV file (e.g., 'data/weather_stations.csv')\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: The loaded dataset\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 1: Import Required Libraries\n",
    "\n",
    "First, let's import the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(f\"✅ Pandas version: {pd.__version__}\")\n",
    "print(\"📚 Ready to work with data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📁 Step 2: Understanding File Paths\n",
    "\n",
    "Before we load data, let's understand where our files are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what files we have in the data directory\n",
    "data_dir = '../data'  # Go up one level from notebooks, then into data\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"📂 Files in data directory:\")\n",
    "    for file in os.listdir(data_dir):\n",
    "        print(f\"   {file}\")\nelse:\n",
    "    print(f\"❌ Directory not found: {data_dir}\")\n",
    "    print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 3: Loading Your First CSV File\n",
    "\n",
    "Now let's load the weather stations data and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '../data/weather_stations.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"✅ File loaded successfully!\")\n",
    "    print(f\"📁 Loaded: {file_path}\")\nexcept FileNotFoundError:\n",
    "    print(f\"❌ File not found: {file_path}\")\n",
    "    print(\"Make sure you're running this from the notebooks directory!\")\nexcept Exception as e:\n",
    "    print(f\"❌ Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 4: Exploring the Dataset Shape and Structure\n",
    "\n",
    "When you first load data, you want to understand:\n",
    "- How many rows and columns does it have?\n",
    "- What are the column names?\n",
    "- What data types are in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape (rows, columns)\n",
    "print(f\"📏 Shape: {df.shape} - {df.shape[0]} rows and {df.shape[1]} columns\")\nprint()\n",
    "\n",
    "# Show column names\n",
    "print(\"📋 Columns:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"   {i+1}. {col}\")\nprint()\n",
    "\n",
    "# Show data types and memory usage\n",
    "print(\"🔧 Data Types and Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👀 Step 5: Looking at the Actual Data\n",
    "\n",
    "Numbers and column names are helpful, but you need to see the actual data to understand what you're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 rows\n",
    "print(\"🔍 First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# You can also show the last few rows\n",
    "print(\"🔍 Last 3 rows:\")\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Step 6: Summary Statistics\n",
    "\n",
    "Summary statistics help you understand the range and distribution of numerical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics for numerical columns\n",
    "print(\"📊 Summary Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# For text columns, you can see unique values\n",
    "print(\"\\n📝 Text Column Analysis:\")\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"   {col}: {unique_count} unique values\")\n",
    "    if unique_count <= 10:  # Show values if not too many\n",
    "        print(f\"      Values: {list(df[col].unique())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Step 7: Checking for Data Quality Issues\n",
    "\n",
    "Real-world data often has problems. Let's check for common issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"🔍 Missing Values Check:\")\n",
    "missing_data = df.isnull().sum()\n",
    "if missing_data.sum() > 0:\n",
    "    print(missing_data[missing_data > 0])\nelse:\n",
    "    print(\"✅ No missing values found!\")\n",
    "\n",
    "print(\"\\n🔍 Duplicate Rows Check:\")\n",
    "duplicate_count = df.duplicated().sum()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"⚠️  Found {duplicate_count} duplicate rows\")\nelse:\n",
    "    print(\"✅ No duplicate rows found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Step 8: Test with the Temperature Readings Data\n",
    "\n",
    "Let's try our exploration technique with the other dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the temperature readings dataset\n",
    "temp_file = '../data/temperature_readings.csv'\n",
    "temp_df = pd.read_csv(temp_file)\n",
    "\n",
    "print(f\"🌡️  Temperature Readings Dataset\")\n",
    "print(f\"Shape: {temp_df.shape}\")\n",
    "print(f\"Columns: {list(temp_df.columns)}\")\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "display(temp_df.head(3))\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(temp_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Step 9: Building the Complete Function\n",
    "\n",
    "Now let's put everything together into a reusable function. This is what you'll implement in `src/pandas_basics.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_gis_data(file_path):\n",
    "    \"\"\"\n",
    "    Load a CSV file and display comprehensive information about the dataset.\n",
    "    \n",
    "    This function demonstrates the first step in any data analysis project:\n",
    "    understanding your data through exploration.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file to load\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The loaded dataset, or None if loading failed\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"LOADING AND EXPLORING GIS DATA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ ERROR: File not found: {file_path}\")\n",
    "        print(\"Please check:\")\n",
    "        print(\"- Is the file path correct?\")\n",
    "        print(\"- Are you in the right directory?\")\n",
    "        print(\"- Does the file exist?\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📁 Loading data from: {file_path}\")\n",
    "    \n",
    "    # Step 2: Load the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"✅ File loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Show basic dataset information\n",
    "    print(f\"\\n📊 DATASET OVERVIEW\")\n",
    "    print(f\"Shape: {df.shape} - {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Step 4: Show data types\n",
    "    print(f\"\\n🔧 DATA TYPES:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"   {col}: {df[col].dtype}\")\n",
    "    \n",
    "    # Step 5: Show first few rows\n",
    "    print(f\"\\n👀 FIRST 5 ROWS:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Step 6: Show summary statistics\n",
    "    print(f\"\\n📈 SUMMARY STATISTICS:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Step 7: Check for data quality issues\n",
    "    print(f\"\\n🔍 DATA QUALITY CHECK:\")\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"Missing values found:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"✅ No missing values\")\n",
    "        \n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"⚠️  Found {duplicates} duplicate rows\")\n",
    "    else:\n",
    "        print(\"✅ No duplicate rows\")\n",
    "    \n",
    "    print(f\"\\n🎉 Data exploration complete! Dataset is ready for analysis.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✨ Step 10: Test Your Function\n",
    "\n",
    "Let's test our complete function with both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with weather stations\n",
    "print(\"🧪 TESTING WITH WEATHER STATIONS DATA\\n\")\n",
    "stations_df = load_and_explore_gis_data('../data/weather_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with temperature readings\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"🧪 TESTING WITH TEMPERATURE READINGS DATA\\n\")\n",
    "readings_df = load_and_explore_gis_data('../data/temperature_readings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error handling with non-existent file\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"🧪 TESTING ERROR HANDLING\\n\")\n",
    "result = load_and_explore_gis_data('../data/nonexistent_file.csv')\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Your Assignment Task\n",
    "\n",
    "Now that you understand how this function works:\n",
    "\n",
    "1. **Go to `src/pandas_basics.py`**\n",
    "2. **Find the `load_and_explore_gis_data()` function**\n",
    "3. **Replace the TODO comments with your implementation**\n",
    "4. **Test your function with pytest**:\n",
    "\n",
    "```bash\n",
    "# Test just this function\n",
    "uv run pytest tests/test_pandas_basics.py::test_load_and_explore_gis_data -v\n",
    "\n",
    "# Test all functions\n",
    "uv run pytest tests/ -v\n",
    "```\n",
    "\n",
    "## 🔑 Key Learning Points\n",
    "\n",
    "- **`pd.read_csv()`** loads CSV files into DataFrames\n",
    "- **`.shape`** tells you rows and columns: `(rows, columns)`\n",
    "- **`.head()`** shows the first few rows\n",
    "- **`.info()`** shows data types and memory usage\n",
    "- **`.describe()`** shows summary statistics for numerical columns\n",
    "- **Always check for missing values and data quality issues**\n",
    "- **Error handling makes your code robust and user-friendly**\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "Once this function works and passes the tests, move on to:\n",
    "- **Function 2**: `filter_environmental_data()` - Learn to filter data based on conditions\n",
    "- **Function 3**: `calculate_station_statistics()` - Learn to group and calculate statistics\n",
    "- **Function 4**: `join_station_data()` - Learn to combine datasets\n",
    "- **Function 5**: `save_processed_data()` - Learn to save your results\n",
    "\n",
    "**Good luck! 🍀**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
