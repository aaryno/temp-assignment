{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function 1: Load and Explore GIS Data ğŸ“Š\n",
    "\n",
    "**Welcome to your first pandas function!**\n",
    "\n",
    "In this notebook, you'll learn how to build the `load_and_explore_gis_data()` function step by step. This is like opening a spreadsheet file and getting familiar with what's inside.\n",
    "\n",
    "## ğŸ¯ What This Function Does\n",
    "- Loads a CSV file into a pandas DataFrame\n",
    "- Shows you key information about the dataset\n",
    "- Displays the first few rows so you can see what the data looks like\n",
    "- Provides summary statistics\n",
    "- Handles errors gracefully\n",
    "\n",
    "## ğŸ”§ Function Signature\n",
    "```python\n",
    "def load_and_explore_gis_data(file_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        file_path (str): Path to CSV file (e.g., 'data/weather_stations.csv')\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: The loaded dataset\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 1: Import Required Libraries\n",
    "\n",
    "First, let's import the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(f\"âœ… Pandas version: {pd.__version__}\")\n",
    "print(\"ğŸ“š Ready to work with data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 2: Understanding File Paths\n",
    "\n",
    "Before we load data, let's understand where our files are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what files we have in the data directory\n",
    "data_dir = '../data'  # Go up one level from notebooks, then into data\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"ğŸ“‚ Files in data directory:\")\n",
    "    for file in os.listdir(data_dir):\n",
    "        print(f\"   {file}\")\nelse:\n",
    "    print(f\"âŒ Directory not found: {data_dir}\")\n",
    "    print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 3: Loading Your First CSV File\n",
    "\n",
    "Now let's load the weather stations data and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '../data/weather_stations.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"âœ… File loaded successfully!\")\n",
    "    print(f\"ğŸ“ Loaded: {file_path}\")\nexcept FileNotFoundError:\n",
    "    print(f\"âŒ File not found: {file_path}\")\n",
    "    print(\"Make sure you're running this from the notebooks directory!\")\nexcept Exception as e:\n",
    "    print(f\"âŒ Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Step 4: Exploring the Dataset Shape and Structure\n",
    "\n",
    "When you first load data, you want to understand:\n",
    "- How many rows and columns does it have?\n",
    "- What are the column names?\n",
    "- What data types are in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape (rows, columns)\n",
    "print(f\"ğŸ“ Shape: {df.shape} - {df.shape[0]} rows and {df.shape[1]} columns\")\nprint()\n",
    "\n",
    "# Show column names\n",
    "print(\"ğŸ“‹ Columns:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"   {i+1}. {col}\")\nprint()\n",
    "\n",
    "# Show data types and memory usage\n",
    "print(\"ğŸ”§ Data Types and Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘€ Step 5: Looking at the Actual Data\n",
    "\n",
    "Numbers and column names are helpful, but you need to see the actual data to understand what you're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 rows\n",
    "print(\"ğŸ” First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# You can also show the last few rows\n",
    "print(\"ğŸ” Last 3 rows:\")\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 6: Summary Statistics\n",
    "\n",
    "Summary statistics help you understand the range and distribution of numerical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics for numerical columns\n",
    "print(\"ğŸ“Š Summary Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# For text columns, you can see unique values\n",
    "print(\"\\nğŸ“ Text Column Analysis:\")\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"   {col}: {unique_count} unique values\")\n",
    "    if unique_count <= 10:  # Show values if not too many\n",
    "        print(f\"      Values: {list(df[col].unique())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 7: Checking for Data Quality Issues\n",
    "\n",
    "Real-world data often has problems. Let's check for common issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"ğŸ” Missing Values Check:\")\n",
    "missing_data = df.isnull().sum()\n",
    "if missing_data.sum() > 0:\n",
    "    print(missing_data[missing_data > 0])\nelse:\n",
    "    print(\"âœ… No missing values found!\")\n",
    "\n",
    "print(\"\\nğŸ” Duplicate Rows Check:\")\n",
    "duplicate_count = df.duplicated().sum()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"âš ï¸  Found {duplicate_count} duplicate rows\")\nelse:\n",
    "    print(\"âœ… No duplicate rows found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 8: Test with the Temperature Readings Data\n",
    "\n",
    "Let's try our exploration technique with the other dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the temperature readings dataset\n",
    "temp_file = '../data/temperature_readings.csv'\n",
    "temp_df = pd.read_csv(temp_file)\n",
    "\n",
    "print(f\"ğŸŒ¡ï¸  Temperature Readings Dataset\")\n",
    "print(f\"Shape: {temp_df.shape}\")\n",
    "print(f\"Columns: {list(temp_df.columns)}\")\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "display(temp_df.head(3))\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(temp_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Step 9: Building the Complete Function\n",
    "\n",
    "Now let's put everything together into a reusable function. This is what you'll implement in `src/pandas_basics.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_gis_data(file_path):\n",
    "    \"\"\"\n",
    "    Load a CSV file and display comprehensive information about the dataset.\n",
    "    \n",
    "    This function demonstrates the first step in any data analysis project:\n",
    "    understanding your data through exploration.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file to load\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The loaded dataset, or None if loading failed\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"LOADING AND EXPLORING GIS DATA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ ERROR: File not found: {file_path}\")\n",
    "        print(\"Please check:\")\n",
    "        print(\"- Is the file path correct?\")\n",
    "        print(\"- Are you in the right directory?\")\n",
    "        print(\"- Does the file exist?\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸ“ Loading data from: {file_path}\")\n",
    "    \n",
    "    # Step 2: Load the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"âœ… File loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ERROR loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Show basic dataset information\n",
    "    print(f\"\\nğŸ“Š DATASET OVERVIEW\")\n",
    "    print(f\"Shape: {df.shape} - {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Step 4: Show data types\n",
    "    print(f\"\\nğŸ”§ DATA TYPES:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"   {col}: {df[col].dtype}\")\n",
    "    \n",
    "    # Step 5: Show first few rows\n",
    "    print(f\"\\nğŸ‘€ FIRST 5 ROWS:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Step 6: Show summary statistics\n",
    "    print(f\"\\nğŸ“ˆ SUMMARY STATISTICS:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Step 7: Check for data quality issues\n",
    "    print(f\"\\nğŸ” DATA QUALITY CHECK:\")\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"Missing values found:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"âœ… No missing values\")\n",
    "        \n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"âš ï¸  Found {duplicates} duplicate rows\")\n",
    "    else:\n",
    "        print(\"âœ… No duplicate rows\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Data exploration complete! Dataset is ready for analysis.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ¨ Step 10: Test Your Function\n",
    "\n",
    "Let's test our complete function with both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with weather stations\n",
    "print(\"ğŸ§ª TESTING WITH WEATHER STATIONS DATA\\n\")\n",
    "stations_df = load_and_explore_gis_data('../data/weather_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with temperature readings\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"ğŸ§ª TESTING WITH TEMPERATURE READINGS DATA\\n\")\n",
    "readings_df = load_and_explore_gis_data('../data/temperature_readings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error handling with non-existent file\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"ğŸ§ª TESTING ERROR HANDLING\\n\")\n",
    "result = load_and_explore_gis_data('../data/nonexistent_file.csv')\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Your Assignment Task\n",
    "\n",
    "Now that you understand how this function works:\n",
    "\n",
    "1. **Go to `src/pandas_basics.py`**\n",
    "2. **Find the `load_and_explore_gis_data()` function**\n",
    "3. **Replace the TODO comments with your implementation**\n",
    "4. **Test your function with pytest**:\n",
    "\n",
    "```bash\n",
    "# Test just this function\n",
    "uv run pytest tests/test_pandas_basics.py::test_load_and_explore_gis_data -v\n",
    "\n",
    "# Test all functions\n",
    "uv run pytest tests/ -v\n",
    "```\n",
    "\n",
    "## ğŸ”‘ Key Learning Points\n",
    "\n",
    "- **`pd.read_csv()`** loads CSV files into DataFrames\n",
    "- **`.shape`** tells you rows and columns: `(rows, columns)`\n",
    "- **`.head()`** shows the first few rows\n",
    "- **`.info()`** shows data types and memory usage\n",
    "- **`.describe()`** shows summary statistics for numerical columns\n",
    "- **Always check for missing values and data quality issues**\n",
    "- **Error handling makes your code robust and user-friendly**\n",
    "\n",
    "## ğŸš€ Next Steps\n",
    "\n",
    "Once this function works and passes the tests, move on to:\n",
    "- **Function 2**: `filter_environmental_data()` - Learn to filter data based on conditions\n",
    "- **Function 3**: `calculate_station_statistics()` - Learn to group and calculate statistics\n",
    "- **Function 4**: `join_station_data()` - Learn to combine datasets\n",
    "- **Function 5**: `save_processed_data()` - Learn to save your results\n",
    "\n",
    "**Good luck! ğŸ€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
