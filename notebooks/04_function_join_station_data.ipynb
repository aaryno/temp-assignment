{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔗 Function 4: Join Station Data\n",
    "\n",
    "## Building the `join_station_data` Function\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand data joining and merging operations in pandas\n",
    "- Learn different types of joins (inner, left, right, outer)\n",
    "- Master the `.merge()` function and join keys\n",
    "- Handle missing data and validate join results\n",
    "- Combine datasets from different sources\n",
    "\n",
    "**Professional Context:**\n",
    "Data joining is essential for:\n",
    "- **Combining datasets** - Merge station metadata with sensor readings\n",
    "- **Data enrichment** - Add geographic coordinates, station names, and location details\n",
    "- **Analysis preparation** - Create complete datasets with all necessary information\n",
    "- **Quality assurance** - Identify stations with missing metadata or readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Data Joins\n",
    "\n",
    "### 1.1 What is a Data Join?\n",
    "\n",
    "**Data joining** is combining two datasets based on a common column (called a \"key\").\n",
    "\n",
    "**Example scenario:**\n",
    "- Dataset 1: **Sensor readings** (station_id, temperature, humidity)\n",
    "- Dataset 2: **Station metadata** (station_id, station_name, latitude, longitude)\n",
    "- **Goal**: Combine them to get readings WITH station details\n",
    "\n",
    "The **join key** is `station_id` - the column that exists in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create sample datasets for demonstration\n",
    "readings_data = pd.DataFrame({\n",
    "    'station_id': ['STN_001', 'STN_002', 'STN_001', 'STN_003', 'STN_002'],\n",
    "    'temperature_c': [22.5, 19.3, 23.1, 16.8, 20.1],\n",
    "    'humidity_percent': [65.2, 78.1, 63.9, 82.3, 76.5],\n",
    "    'reading_time': ['2024-01-01 08:00', '2024-01-01 08:00', '2024-01-01 12:00', '2024-01-01 08:00', '2024-01-01 12:00']\n",
    "})\n",
    "\n",
    "stations_metadata = pd.DataFrame({\n",
    "    'station_id': ['STN_001', 'STN_002', 'STN_003', 'STN_004'],\n",
    "    'station_name': ['Downtown Plaza', 'Coastal Park', 'Mountain Ridge', 'Airport Terminal'],\n",
    "    'latitude': [40.123, 40.789, 41.234, 40.567],\n",
    "    'longitude': [-74.456, -73.987, -74.567, -74.123],\n",
    "    'elevation_m': [10, 5, 450, 25]\n",
    "})\n",
    "\n",
    "print(\"READINGS DATA:\")\n",
    "print(readings_data)\n",
    "print(\"\\nSTATIONS METADATA:\")\n",
    "print(stations_metadata)\n",
    "\n",
    "print(\"\\nKEY OBSERVATIONS:\")\n",
    "print(f\"Stations in readings: {sorted(readings_data['station_id'].unique())}\")\n",
    "print(f\"Stations in metadata: {sorted(stations_metadata['station_id'].unique())}\")\n",
    "print(f\"STN_004 has metadata but no readings (common scenario)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Types of Joins\n",
    "\n",
    "There are four main types of joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DIFFERENT JOIN TYPES ===\")\n",
    "\n",
    "# 1. INNER JOIN - Only records that exist in BOTH datasets\n",
    "inner_join = pd.merge(readings_data, stations_metadata, on='station_id', how='inner')\n",
    "print(f\"\\n1. INNER JOIN: {len(inner_join)} rows\")\n",
    "print(\"   Includes only stations with BOTH readings AND metadata\")\n",
    "print(inner_join[['station_id', 'temperature_c', 'station_name']].head())\n",
    "\n",
    "# 2. LEFT JOIN - All readings, add metadata where available\n",
    "left_join = pd.merge(readings_data, stations_metadata, on='station_id', how='left')\n",
    "print(f\"\\n2. LEFT JOIN: {len(left_join)} rows\")\n",
    "print(\"   Includes ALL readings, adds metadata where available\")\n",
    "print(left_join[['station_id', 'temperature_c', 'station_name']].head())\n",
    "\n",
    "# 3. RIGHT JOIN - All stations, add readings where available\n",
    "right_join = pd.merge(readings_data, stations_metadata, on='station_id', how='right')\n",
    "print(f\"\\n3. RIGHT JOIN: {len(right_join)} rows\")\n",
    "print(\"   Includes ALL stations, adds readings where available\")\n",
    "print(right_join[['station_id', 'temperature_c', 'station_name']].head())\n",
    "\n",
    "# 4. OUTER JOIN - Everything from both datasets\n",
    "outer_join = pd.merge(readings_data, stations_metadata, on='station_id', how='outer')\n",
    "print(f\"\\n4. OUTER JOIN: {len(outer_join)} rows\")\n",
    "print(\"   Includes ALL readings AND all stations\")\n",
    "print(outer_join[['station_id', 'temperature_c', 'station_name']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing Data Joins\n",
    "\n",
    "### 2.1 Basic Merge Operations\n",
    "\n",
    "The pandas `.merge()` function is the primary tool for joining data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate basic merge syntax\n",
    "print(\"=== PANDAS MERGE FUNCTION ===\")\n",
    "print(\"Basic syntax: pd.merge(left_df, right_df, on='key_column', how='join_type')\")\n",
    "\n",
    "# Perform left join (most common for this use case)\n",
    "joined_data = pd.merge(\n",
    "    left=readings_data,\n",
    "    right=stations_metadata, \n",
    "    on='station_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nJoined data shape: {joined_data.shape}\")\n",
    "print(f\"Columns: {list(joined_data.columns)}\")\n",
    "\n",
    "print(\"\\nJoined data sample:\")\n",
    "display_cols = ['station_id', 'temperature_c', 'station_name', 'latitude', 'longitude']\n",
    "print(joined_data[display_cols].head())\n",
    "\n",
    "# Check for missing metadata\n",
    "missing_metadata = joined_data['station_name'].isna().sum()\n",
    "print(f\"\\nReadings with missing metadata: {missing_metadata}\")\n",
    "\n",
    "if missing_metadata > 0:\n",
    "    missing_stations = joined_data[joined_data['station_name'].isna()]['station_id'].unique()\n",
    "    print(f\"Stations missing metadata: {list(missing_stations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Join Validation and Quality Checking\n",
    "\n",
    "After joining, always validate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze join results\n",
    "print(\"=== JOIN VALIDATION ===\")\n",
    "\n",
    "print(f\"Original readings: {len(readings_data)}\")\n",
    "print(f\"After join: {len(joined_data)}\")\n",
    "print(f\"Records with complete data: {joined_data['station_name'].notna().sum()}\")\n",
    "\n",
    "# Data completeness by station\n",
    "completeness = joined_data.groupby('station_id').agg({\n",
    "    'temperature_c': 'count',\n",
    "    'station_name': lambda x: x.notna().all()\n",
    "}).round(1)\n",
    "completeness.columns = ['reading_count', 'has_metadata']\n",
    "\n",
    "print(\"\\nCompleteness by station:\")\n",
    "print(completeness)\n",
    "\n",
    "# Summary report\n",
    "complete_stations = completeness[completeness['has_metadata'] == True]\n",
    "incomplete_stations = completeness[completeness['has_metadata'] == False]\n",
    "\n",
    "print(f\"\\nStations with complete metadata: {len(complete_stations)}\")\n",
    "print(f\"Stations missing metadata: {len(incomplete_stations)}\")\n",
    "\n",
    "if len(incomplete_stations) > 0:\n",
    "    affected_readings = incomplete_stations['reading_count'].sum()\n",
    "    total_readings = completeness['reading_count'].sum()\n",
    "    print(f\"Readings affected: {affected_readings} out of {total_readings} ({100*affected_readings/total_readings:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Complete Function\n",
    "\n",
    "### 3.1 Complete Function Implementation\n",
    "\n",
    "Now let's build the complete function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_station_data_example(readings_df, stations_df):\n",
    "    \"\"\"Example implementation of the join_station_data function.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"JOINING STATION DATA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Input validation\n",
    "    if readings_df is None or len(readings_df) == 0:\n",
    "        print(\"Error: Readings DataFrame is empty or None\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if stations_df is None or len(stations_df) == 0:\n",
    "        print(\"Error: Stations DataFrame is empty or None\") \n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Check for required join key\n",
    "    if 'station_id' not in readings_df.columns:\n",
    "        print(\"Error: 'station_id' column missing from readings data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if 'station_id' not in stations_df.columns:\n",
    "        print(\"Error: 'station_id' column missing from stations data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Print input summary\n",
    "    print(f\"Input data:\")\n",
    "    print(f\"  Readings: {len(readings_df)} rows, {len(readings_df.columns)} columns\")\n",
    "    print(f\"  Stations: {len(stations_df)} rows, {len(stations_df.columns)} columns\")\n",
    "    \n",
    "    # Analyze join keys\n",
    "    readings_stations = set(readings_df['station_id'].unique())\n",
    "    metadata_stations = set(stations_df['station_id'].unique())\n",
    "    \n",
    "    print(f\"\\nJoin analysis:\")\n",
    "    print(f\"  Stations in readings: {len(readings_stations)}\")\n",
    "    print(f\"  Stations in metadata: {len(metadata_stations)}\")\n",
    "    print(f\"  Stations in both: {len(readings_stations & metadata_stations)}\")\n",
    "    \n",
    "    if readings_stations - metadata_stations:\n",
    "        print(f\"  ⚠️ Readings without metadata: {readings_stations - metadata_stations}\")\n",
    "    if metadata_stations - readings_stations:\n",
    "        print(f\"  ℹ️ Metadata without readings: {metadata_stations - readings_stations}\")\n",
    "    \n",
    "    # Perform left join to keep all readings\n",
    "    print(f\"\\nPerforming LEFT JOIN (keeping all readings)...\")\n",
    "    result = pd.merge(readings_df, stations_df, on='station_id', how='left')\n",
    "    \n",
    "    # Validate results\n",
    "    missing_metadata_count = result.isnull().any(axis=1).sum()\n",
    "    complete_records = len(result) - missing_metadata_count\n",
    "    \n",
    "    print(f\"\\nJoin results:\")\n",
    "    print(f\"  Total records: {len(result)}\")\n",
    "    print(f\"  Complete records: {complete_records}\")\n",
    "    print(f\"  Records with missing metadata: {missing_metadata_count}\")\n",
    "    print(f\"  Data completeness: {100*complete_records/len(result):.1f}%\")\n",
    "    \n",
    "    print(\"\\n✅ Station data join completed successfully!\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the function\n",
    "test_result = join_station_data_example(readings_data, stations_metadata)\n",
    "print(\"\\n=== FINAL RESULT ===\")\n",
    "print(test_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Your Implementation Task\n",
    "\n",
    "### 4.1 Implementation Guidelines\n",
    "\n",
    "Now implement this function in `src/pandas_basics.py`. Key steps:\n",
    "\n",
    "```python\n",
    "def join_station_data(readings_df, stations_df):\n",
    "    # TODO: Print header\n",
    "    # TODO: Validate both input DataFrames (check if None or empty)\n",
    "    # TODO: Check for 'station_id' column in both DataFrames\n",
    "    # TODO: Print input data summary\n",
    "    # TODO: Analyze join keys (stations in each dataset)\n",
    "    # TODO: Perform LEFT JOIN using pd.merge()\n",
    "    # TODO: Validate join results\n",
    "    # TODO: Print completion message and statistics\n",
    "    # TODO: Return joined DataFrame\n",
    "```\n",
    "\n",
    "### 4.2 Testing Your Implementation\n",
    "\n",
    "```bash\n",
    "uv run pytest tests/test_pandas_basics.py::test_join_station_data -v\n",
    "```\n",
    "\n",
    "### 4.3 Key Requirements\n",
    "\n",
    "- Use **LEFT JOIN** to keep all readings\n",
    "- Join on `'station_id'` column\n",
    "- Handle missing metadata gracefully\n",
    "- Return the complete joined DataFrame\n",
    "- Provide informative error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Summary and Next Steps\n",
    "\n",
    "### What You've Learned\n",
    "- How to join datasets using pandas `.merge()`\n",
    "- Different types of joins and when to use them\n",
    "- Validating join results and handling missing data\n",
    "- Professional data integration workflows\n",
    "\n",
    "### Your Implementation Checklist\n",
    "- [ ] Validate both input DataFrames\n",
    "- [ ] Check for required 'station_id' column\n",
    "- [ ] Analyze join keys before merging\n",
    "- [ ] Use LEFT JOIN with `how='left'`\n",
    "- [ ] Report join statistics and data completeness\n",
    "- [ ] Return properly merged DataFrame\n",
    "\n",
    "### Next Function\n",
    "Once implemented and tested, move on to:\n",
    "**[`05_function_save_processed_data.ipynb`](05_function_save_processed_data.ipynb)**\n",
    "\n",
    "Where you'll learn to save your processed data for future use!\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Data joining is like connecting puzzle pieces - make sure the pieces fit together properly! 🧩"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
